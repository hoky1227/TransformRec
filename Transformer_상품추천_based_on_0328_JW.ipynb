{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transformer 상품추천 based on_0328_JW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3fc94f669f9d4e478ceda1b183ff0352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61b1ea5f0c064860bfbcd4251a1bc3eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61fea5e35eef4271bbba41dd0021ac5b",
              "IPY_MODEL_bb3ab6e6e6da4141b8a0b0b43821ca67"
            ]
          }
        },
        "61b1ea5f0c064860bfbcd4251a1bc3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61fea5e35eef4271bbba41dd0021ac5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b71bad4901bf4f149ae7e13dfd05891b",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 56964,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 56,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41df36ec45834950a012d5a8fb5bcfe0"
          }
        },
        "bb3ab6e6e6da4141b8a0b0b43821ca67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45f7508470274d5994612a43ba100b0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 56/56964 [2:50:46&lt;10:48:31,  1.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fafcc35bdc5f4b07827c6671d738de5d"
          }
        },
        "b71bad4901bf4f149ae7e13dfd05891b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41df36ec45834950a012d5a8fb5bcfe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45f7508470274d5994612a43ba100b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fafcc35bdc5f4b07827c6671d738de5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e7843f066d84df6b4f5ecba8bace362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45c535617eee45c29f534b0c5caf0013",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03f481cd91fa4d168275e1afeb56c750",
              "IPY_MODEL_8424a98b7621427bb707a6b6937b9b7b"
            ]
          }
        },
        "45c535617eee45c29f534b0c5caf0013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03f481cd91fa4d168275e1afeb56c750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f2e2f186695b4aa39320fafedb23617a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14241,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14241,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a485b6c166ae4662b1a827c91ebf3db4"
          }
        },
        "8424a98b7621427bb707a6b6937b9b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3522afecae2642ad869b75e6b4fb65fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14241/14241 [2:49:57&lt;00:00,  1.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c413906413e54659b430646a7982e457"
          }
        },
        "f2e2f186695b4aa39320fafedb23617a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a485b6c166ae4662b1a827c91ebf3db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3522afecae2642ad869b75e6b4fb65fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c413906413e54659b430646a7982e457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoky1227/Transformer_based-recommendation/blob/main/Transformer_%EC%83%81%ED%92%88%EC%B6%94%EC%B2%9C_based_on_0328_JW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsJc4nu7CBFk",
        "outputId": "2ccee6a3-2f1b-4204-a558-bb4e787a3cb4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrwXm8HTWl_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5a78fa-287f-48ea-8ec4-e2bdcdec0290"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install tensorflow-addons\n",
        "!pip install -q pyyaml h5py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 20.0MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=a3815e2f752b62daaffd5b6a917046ffddad1ebeb8276a26d80cdb2593c8a5dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 19.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqIBocN1XMe7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dateutil.parser import parse\n",
        "from tqdm import tqdm_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTYLa1rrCY80"
      },
      "source": [
        "#### 내 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "65jRNKKyCgRs",
        "outputId": "82eeef4c-f81d-4c90-cebf-8a2490324969"
      },
      "source": [
        "data = pd.read_csv(path + 'data_cutted_5.csv')\n",
        "data.pop('Unnamed: 0')\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Detail</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S/4 CACTI CANDLES&amp;&amp;HOLIDAY FUN LUDO&amp;&amp;CAT BOWL&amp;...</td>\n",
              "      <td>PINK FLORAL FELTCRAFT SHOULDER BAG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SILK PURSE RUSSIAN DOLL BLUE&amp;&amp;LOVE BUILDING BL...</td>\n",
              "      <td>BLUE GREEN EMBROIDERY COSMETIC BAG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RIBBON REEL STRIPES DESIGN&amp;&amp;RIBBON REEL SPOTS ...</td>\n",
              "      <td>GLASS ETCHED T-LIGHT HOLDER MEDIUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ETCHED GLASS COASTER&amp;&amp;PACK OF 20 SKULL PAPER N...</td>\n",
              "      <td>HANGING HEART ZINC T-LIGHT HOLDER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PLASTERS IN TIN WOODLAND ANIMALS&amp;&amp;PLASTERS IN ...</td>\n",
              "      <td>LUNCH BAG SPACEBOY DESIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71200</th>\n",
              "      <td>ENAMEL MEASURING JUG CREAM&amp;&amp;CREAM HEART CARD H...</td>\n",
              "      <td>IVORY KITCHEN SCALES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71201</th>\n",
              "      <td>TOILET METAL SIGN&amp;&amp;SAVE THE PLANET MUG&amp;&amp;KINGS ...</td>\n",
              "      <td>POTTERING IN THE SHED METAL SIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71202</th>\n",
              "      <td>IVORY HANGING DECORATION  HEART&amp;&amp;HEART IVORY T...</td>\n",
              "      <td>COLOUR GLASS T-LIGHT HOLDER HANGING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71203</th>\n",
              "      <td>LAVENDER SCENTED FABRIC HEART&amp;&amp;PLACE SETTING W...</td>\n",
              "      <td>MURANO STYLE GLASS BRACELET PINK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71204</th>\n",
              "      <td>FELT EGG COSY CHICKEN&amp;&amp;APPLE BATH SPONGE&amp;&amp;RED ...</td>\n",
              "      <td>VINTAGE CARAVAN GIFT WRAP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71205 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Detail                                label\n",
              "0      S/4 CACTI CANDLES&&HOLIDAY FUN LUDO&&CAT BOWL&...   PINK FLORAL FELTCRAFT SHOULDER BAG\n",
              "1      SILK PURSE RUSSIAN DOLL BLUE&&LOVE BUILDING BL...   BLUE GREEN EMBROIDERY COSMETIC BAG\n",
              "2      RIBBON REEL STRIPES DESIGN&&RIBBON REEL SPOTS ...   GLASS ETCHED T-LIGHT HOLDER MEDIUM\n",
              "3      ETCHED GLASS COASTER&&PACK OF 20 SKULL PAPER N...    HANGING HEART ZINC T-LIGHT HOLDER\n",
              "4      PLASTERS IN TIN WOODLAND ANIMALS&&PLASTERS IN ...            LUNCH BAG SPACEBOY DESIGN\n",
              "...                                                  ...                                  ...\n",
              "71200  ENAMEL MEASURING JUG CREAM&&CREAM HEART CARD H...                 IVORY KITCHEN SCALES\n",
              "71201  TOILET METAL SIGN&&SAVE THE PLANET MUG&&KINGS ...     POTTERING IN THE SHED METAL SIGN\n",
              "71202  IVORY HANGING DECORATION  HEART&&HEART IVORY T...  COLOUR GLASS T-LIGHT HOLDER HANGING\n",
              "71203  LAVENDER SCENTED FABRIC HEART&&PLACE SETTING W...     MURANO STYLE GLASS BRACELET PINK\n",
              "71204  FELT EGG COSY CHICKEN&&APPLE BATH SPONGE&&RED ...            VINTAGE CARAVAN GIFT WRAP\n",
              "\n",
              "[71205 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "wSCGdatWEGvU",
        "outputId": "63d167d8-68ff-4b97-e225-88402a69717e"
      },
      "source": [
        "train_df = data.copy()\n",
        "train_df.rename(columns = {'Detail':'train'}, inplace=True)\n",
        "train_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S/4 CACTI CANDLES&amp;&amp;HOLIDAY FUN LUDO&amp;&amp;CAT BOWL&amp;...</td>\n",
              "      <td>PINK FLORAL FELTCRAFT SHOULDER BAG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SILK PURSE RUSSIAN DOLL BLUE&amp;&amp;LOVE BUILDING BL...</td>\n",
              "      <td>BLUE GREEN EMBROIDERY COSMETIC BAG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RIBBON REEL STRIPES DESIGN&amp;&amp;RIBBON REEL SPOTS ...</td>\n",
              "      <td>GLASS ETCHED T-LIGHT HOLDER MEDIUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ETCHED GLASS COASTER&amp;&amp;PACK OF 20 SKULL PAPER N...</td>\n",
              "      <td>HANGING HEART ZINC T-LIGHT HOLDER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PLASTERS IN TIN WOODLAND ANIMALS&amp;&amp;PLASTERS IN ...</td>\n",
              "      <td>LUNCH BAG SPACEBOY DESIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71200</th>\n",
              "      <td>ENAMEL MEASURING JUG CREAM&amp;&amp;CREAM HEART CARD H...</td>\n",
              "      <td>IVORY KITCHEN SCALES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71201</th>\n",
              "      <td>TOILET METAL SIGN&amp;&amp;SAVE THE PLANET MUG&amp;&amp;KINGS ...</td>\n",
              "      <td>POTTERING IN THE SHED METAL SIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71202</th>\n",
              "      <td>IVORY HANGING DECORATION  HEART&amp;&amp;HEART IVORY T...</td>\n",
              "      <td>COLOUR GLASS T-LIGHT HOLDER HANGING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71203</th>\n",
              "      <td>LAVENDER SCENTED FABRIC HEART&amp;&amp;PLACE SETTING W...</td>\n",
              "      <td>MURANO STYLE GLASS BRACELET PINK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71204</th>\n",
              "      <td>FELT EGG COSY CHICKEN&amp;&amp;APPLE BATH SPONGE&amp;&amp;RED ...</td>\n",
              "      <td>VINTAGE CARAVAN GIFT WRAP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71205 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   train                                label\n",
              "0      S/4 CACTI CANDLES&&HOLIDAY FUN LUDO&&CAT BOWL&...   PINK FLORAL FELTCRAFT SHOULDER BAG\n",
              "1      SILK PURSE RUSSIAN DOLL BLUE&&LOVE BUILDING BL...   BLUE GREEN EMBROIDERY COSMETIC BAG\n",
              "2      RIBBON REEL STRIPES DESIGN&&RIBBON REEL SPOTS ...   GLASS ETCHED T-LIGHT HOLDER MEDIUM\n",
              "3      ETCHED GLASS COASTER&&PACK OF 20 SKULL PAPER N...    HANGING HEART ZINC T-LIGHT HOLDER\n",
              "4      PLASTERS IN TIN WOODLAND ANIMALS&&PLASTERS IN ...            LUNCH BAG SPACEBOY DESIGN\n",
              "...                                                  ...                                  ...\n",
              "71200  ENAMEL MEASURING JUG CREAM&&CREAM HEART CARD H...                 IVORY KITCHEN SCALES\n",
              "71201  TOILET METAL SIGN&&SAVE THE PLANET MUG&&KINGS ...     POTTERING IN THE SHED METAL SIGN\n",
              "71202  IVORY HANGING DECORATION  HEART&&HEART IVORY T...  COLOUR GLASS T-LIGHT HOLDER HANGING\n",
              "71203  LAVENDER SCENTED FABRIC HEART&&PLACE SETTING W...     MURANO STYLE GLASS BRACELET PINK\n",
              "71204  FELT EGG COSY CHICKEN&&APPLE BATH SPONGE&&RED ...            VINTAGE CARAVAN GIFT WRAP\n",
              "\n",
              "[71205 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EQmA7cFfS1v"
      },
      "source": [
        "#### 학습 데이터의 토큰 갯수 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIlSDEc3DlJz"
      },
      "source": [
        "train_df['token_len'] = [len(sum([i.split(' ') for i in aaa.split('&&')], [])) for aaa in train_df['train']]\n",
        "\n",
        "token_len_cate = []\n",
        "for i in train_df['token_len']:\n",
        "    if i >= 0 and i < 100:\n",
        "        token_len_cate.append('0:100')\n",
        "    elif i >= 100 and i < 200:\n",
        "        token_len_cate.append('100:200')\n",
        "    elif i >= 200 and i < 300:\n",
        "        token_len_cate.append('200:300')\n",
        "    elif i >= 300 and i < 400:\n",
        "        token_len_cate.append('300:400')\n",
        "    elif i >= 400 and i < 500:\n",
        "        token_len_cate.append('400:500')\n",
        "    elif i >= 500 and i < 600:\n",
        "        token_len_cate.append('500:600')\n",
        "    elif i >= 600 and i < 700:\n",
        "        token_len_cate.append('600:700')\n",
        "    elif i >= 700 and i < 800:\n",
        "        token_len_cate.append('700:800')\n",
        "    elif i >= 800 and i < 900:\n",
        "        token_len_cate.append('800:900')\n",
        "    elif i >= 900:\n",
        "        token_len_cate.append('900:')\n",
        "train_df['token_len_cate'] = token_len_cate"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "OiFp_ehEQSER",
        "outputId": "172ba2d0-8427-4f74-b1e2-78b40fa79275"
      },
      "source": [
        "token_len_sort = sorted({i:j for i, j in zip(train_df['token_len_cate'].value_counts().keys(), train_df['token_len_cate'].value_counts().values)}.items(), key=lambda x:x[0])\n",
        "x = [i for (i,_) in token_len_sort]\n",
        "y = [i for (_,i) in token_len_sort]\n",
        "print(y)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(x, y)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[71205]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXAiNbuTfhlz"
      },
      "source": [
        "#### 토큰 갯수 512 이하로 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClCqbjQdGd0J"
      },
      "source": [
        "filtering_train_df = train_df.copy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8w8eOJQQ3S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16786b66-fbff-41ad-e892-8b4bf60f55ea"
      },
      "source": [
        "filtering_train_df = train_df[train_df['token_len']<400].reset_index(drop=True)\n",
        "filtering_train_df['token_len'].max()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfhU7g2IDC3J"
      },
      "source": [
        "cut = round(len(filtering_train_df) * 0.8)\n",
        "# data.rename(columns = {'Detail':'train'}, inplace=True)\n",
        "filtering_train_df, filtering_test_df = filtering_train_df[:cut], filtering_train_df[cut:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWjyzSEXMqXV"
      },
      "source": [
        "filtering_test_df = filtering_test_df.reset_index(drop=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUsG2iJd8nKn",
        "outputId": "c7b269ed-f040-42cd-9d0a-83b8770642bb"
      },
      "source": [
        "print(len(filtering_train_df))\n",
        "len(filtering_test_df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTDYnAiwlCg6"
      },
      "source": [
        "#### 학습을 위해 토큰으로 자르기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIAMM6IYekZ2"
      },
      "source": [
        "filtering_train_df['split_train_token'] = ['<esp> ' + i.strip().replace('&&', ' <esp> ') + ' <esp>' for i in filtering_train_df['train']]\n",
        "filtering_train_df['split_label_token'] = ['<esp> ' + i.strip() + ' <esp>' for i in filtering_train_df['label']]\n",
        "# filtering_train_df['split_train_token'] = ['<sos> ' + i.strip().replace('&&', ' <eos> ') + ' <eos>' for i in filtering_train_df['train']]\n",
        "# filtering_train_df['split_label_token'] = ['<sos> ' + i.strip() + ' <eos>' for i in filtering_train_df['label']]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "grUN5n41gX2W",
        "outputId": "17b9f660-a927-4f4f-8622-b9e4b0f2b50c"
      },
      "source": [
        "filtering_train_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>label</th>\n",
              "      <th>token_len</th>\n",
              "      <th>token_len_cate</th>\n",
              "      <th>split_train_token</th>\n",
              "      <th>split_label_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S/4 CACTI CANDLES&amp;&amp;HOLIDAY FUN LUDO&amp;&amp;CAT BOWL&amp;...</td>\n",
              "      <td>PINK FLORAL FELTCRAFT SHOULDER BAG</td>\n",
              "      <td>11</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; S/4 CACTI CANDLES &lt;esp&gt; HOLIDAY FUN LUDO...</td>\n",
              "      <td>&lt;esp&gt; PINK FLORAL FELTCRAFT SHOULDER BAG &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SILK PURSE RUSSIAN DOLL BLUE&amp;&amp;LOVE BUILDING BL...</td>\n",
              "      <td>BLUE GREEN EMBROIDERY COSMETIC BAG</td>\n",
              "      <td>19</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; SILK PURSE RUSSIAN DOLL BLUE &lt;esp&gt; LOVE ...</td>\n",
              "      <td>&lt;esp&gt; BLUE GREEN EMBROIDERY COSMETIC BAG &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RIBBON REEL STRIPES DESIGN&amp;&amp;RIBBON REEL SPOTS ...</td>\n",
              "      <td>GLASS ETCHED T-LIGHT HOLDER MEDIUM</td>\n",
              "      <td>17</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; RIBBON REEL STRIPES DESIGN &lt;esp&gt; RIBBON ...</td>\n",
              "      <td>&lt;esp&gt; GLASS ETCHED T-LIGHT HOLDER MEDIUM &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ETCHED GLASS COASTER&amp;&amp;PACK OF 20 SKULL PAPER N...</td>\n",
              "      <td>HANGING HEART ZINC T-LIGHT HOLDER</td>\n",
              "      <td>18</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; ETCHED GLASS COASTER &lt;esp&gt; PACK OF 20 SK...</td>\n",
              "      <td>&lt;esp&gt; HANGING HEART ZINC T-LIGHT HOLDER &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PLASTERS IN TIN WOODLAND ANIMALS&amp;&amp;PLASTERS IN ...</td>\n",
              "      <td>LUNCH BAG SPACEBOY DESIGN</td>\n",
              "      <td>18</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; PLASTERS IN TIN WOODLAND ANIMALS &lt;esp&gt; P...</td>\n",
              "      <td>&lt;esp&gt; LUNCH BAG SPACEBOY DESIGN &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               train  ...                               split_label_token\n",
              "0  S/4 CACTI CANDLES&&HOLIDAY FUN LUDO&&CAT BOWL&...  ...  <esp> PINK FLORAL FELTCRAFT SHOULDER BAG <esp>\n",
              "1  SILK PURSE RUSSIAN DOLL BLUE&&LOVE BUILDING BL...  ...  <esp> BLUE GREEN EMBROIDERY COSMETIC BAG <esp>\n",
              "2  RIBBON REEL STRIPES DESIGN&&RIBBON REEL SPOTS ...  ...  <esp> GLASS ETCHED T-LIGHT HOLDER MEDIUM <esp>\n",
              "3  ETCHED GLASS COASTER&&PACK OF 20 SKULL PAPER N...  ...   <esp> HANGING HEART ZINC T-LIGHT HOLDER <esp>\n",
              "4  PLASTERS IN TIN WOODLAND ANIMALS&&PLASTERS IN ...  ...           <esp> LUNCH BAG SPACEBOY DESIGN <esp>\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y5o1x06Y3Qh"
      },
      "source": [
        "MAX_LENGTH = 128"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vUJ-Vy-Yvnu"
      },
      "source": [
        "# # for i in range(len(train_token)):\n",
        "# #     if len(train_token[i]) > MAX_LENGTH:\n",
        "# #         while 1:\n",
        "# #             id = train_token[i].index('<esp>')\n",
        "# #             train_token[i] = train_token[i][id:]\n",
        "# #             if len(train_token[i]) <= MAX_LENGTH:\n",
        "# #                 break\n",
        "# for i in range(len(filtering_train_df)):\n",
        "#     filtering_train_df['split_train_token'][i] = filtering_train_df['split_train_token'][i].split(' ')\n",
        "#     if len(filtering_train_df['split_train_token'][i]) > MAX_LENGTH:\n",
        "#         while 1:\n",
        "#             id = filtering_train_df['split_train_token'][i].index('<esp>')\n",
        "#             filtering_train_df['split_train_token'][i] = filtering_train_df['split_train_token'][i][id:]\n",
        "#             # tokenized_texts[i][0] = '[CLS]'\n",
        "#             if len(filtering_train_df['split_train_token'][i]) <= MAX_LENGTH:\n",
        "#                 break\n",
        "#     filtering_train_df['split_train_token'][i] = ' '.join(x for x in filtering_train_df['split_train_token'][i])\n",
        "\n",
        "# filtering_train_df.head()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrRaQMinZ0H"
      },
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(filtering_train_df['split_train_token'] + filtering_train_df['split_label_token'], target_vocab_size=2**13)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNc2-ElvnZ7l"
      },
      "source": [
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XNjMLlYnZ9h",
        "outputId": "1373d510-55c1-4ef1-8c1d-f414d717fff7"
      },
      "source": [
        "print('시작 토큰 번호 :',START_TOKEN)\n",
        "print('종료 토큰 번호 :',END_TOKEN)\n",
        "print('단어 집합의 크기 :',VOCAB_SIZE)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "시작 토큰 번호 : [2719]\n",
            "종료 토큰 번호 : [2720]\n",
            "단어 집합의 크기 : 2721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyU2LyVcnZ_u"
      },
      "source": [
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGD78-kOL_wk"
      },
      "source": [
        "train_token, label_token = tokenize_and_filter(filtering_train_df['split_train_token'], filtering_train_df['split_label_token'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNW0IgXRMYfD",
        "outputId": "d185f961-9622-4ae4-fa66-891e187db405"
      },
      "source": [
        "print('질문 데이터의 크기(shape) :', train_token.shape)\n",
        "print('답변 데이터의 크기(shape) :', label_token.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "질문 데이터의 크기(shape) : (56964, 128)\n",
            "답변 데이터의 크기(shape) : (56964, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHi5hUkwF6NG"
      },
      "source": [
        "#### GPU 작동 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMTEg_x0F5wr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f313fb-ae4f-47f7-a921-e4ea66131f5a"
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T3tWOLGGDgI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5145ee1-d7da-4a74-a321-71bcbf811027"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syPtUTKK1fEt"
      },
      "source": [
        "# USE_CUDA = torch.cuda.is_available()\n",
        "# print(USE_CUDA)\n",
        "\n",
        "# device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
        "# print('학습을 진행하는 기기:',device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb_xqSUBw5TI",
        "outputId": "918af616-b5ad-4470-d51e-68cfb262549c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr  2 02:42:55 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    27W /  70W |    222MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo4OnGGzGAGz"
      },
      "source": [
        "#### 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LomtZ4zL0ELY"
      },
      "source": [
        "# import math\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class TransformerModel(nn.Module):\n",
        "\n",
        "#     def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "#         super(TransformerModel, self).__init__()\n",
        "#         from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "#         self.model_type = 'Transformer'\n",
        "#         self.src_mask = None\n",
        "#         self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "#         encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "#         self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "#         self.encoder = nn.Embedding(ntoken, ninp)\n",
        "#         self.ninp = ninp\n",
        "#         self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "#         self.init_weights()\n",
        "\n",
        "#     def _generate_square_subsequent_mask(self, sz):\n",
        "#         mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "#         mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "#         return mask\n",
        "\n",
        "#     def init_weights(self):\n",
        "#         initrange = 0.1\n",
        "#         self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "#         self.decoder.bias.data.zero_()\n",
        "#         self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "#     def forward(self, src):\n",
        "#         if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "#             device = src.device\n",
        "#             mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "#             self.src_mask = mask\n",
        "\n",
        "#         src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "#         src = self.pos_encoder(src)\n",
        "#         output = self.transformer_encoder(src, self.src_mask)\n",
        "#         output = self.decoder(output)\n",
        "#         return output\n",
        "\n",
        "# class PositionalEncoding(nn.Module):\n",
        "\n",
        "#     def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "#         super(PositionalEncoding, self).__init__()\n",
        "#         self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "#         pe = torch.zeros(max_len, d_model)\n",
        "#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
        "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
        "#         pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "#         self.register_buffer('pe', pe)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x + self.pe[:x.size(0), :]\n",
        "#         return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUAoFitg13BG"
      },
      "source": [
        "# import torchtext\n",
        "# from torchtext.data.utils import get_tokenizer\n",
        "# # TEXT = torchtext.data.Field(tokenize=get_tokenizer(\"basic_english\"),\n",
        "# #                             init_token='<sos>',\n",
        "# #                             eos_token='<eos>',\n",
        "# #                             lower=True)\n",
        "# train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT)\n",
        "# TEXT.build_vocab(train_txt)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# def batchify(data, bsz):\n",
        "#     data = TEXT.numericalize([data.examples[0].text])\n",
        "#     # 데이터셋을 bsz 파트들로 나눕니다.\n",
        "#     nbatch = data.size(0) // bsz\n",
        "#     # 깔끔하게 나누어 떨어지지 않는 추가적인 부분(나머지들) 은 잘라냅니다.\n",
        "#     data = data.narrow(0, 0, nbatch * bsz)\n",
        "#     # 데이터에 대하여 bsz 배치들로 동등하게 나눕니다.\n",
        "#     data = data.view(bsz, -1).t().contiguous()\n",
        "#     return data.to(device)\n",
        "\n",
        "# batch_size = 20\n",
        "# eval_batch_size = 10\n",
        "# train_data = batchify(train_txt, batch_size)\n",
        "# val_data = batchify(val_txt, eval_batch_size)\n",
        "# test_data = batchify(test_txt, eval_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHiasLbC2bev"
      },
      "source": [
        "# criterion = nn.CrossEntropyLoss()\n",
        "# lr = 5.0 # 학습률\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "# import time\n",
        "# def train():\n",
        "#     model.train() # 학습 모드를 시작합니다.\n",
        "#     total_loss = 0.\n",
        "#     start_time = time.time()\n",
        "#     ntokens = len(TEXT.vocab.stoi)\n",
        "#     for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "#         data, targets = get_batch(train_data, i)\n",
        "#         optimizer.zero_grad()\n",
        "#         output = model(data)\n",
        "#         loss = criterion(output.view(-1, ntokens), targets)\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "#         log_interval = 200\n",
        "#         if batch % log_interval == 0 and batch > 0:\n",
        "#             cur_loss = total_loss / log_interval\n",
        "#             elapsed = time.time() - start_time\n",
        "#             print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "#                   'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "#                   'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "#                     epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
        "#                     elapsed * 1000 / log_interval,\n",
        "#                     cur_loss, math.exp(cur_loss)))\n",
        "#             total_loss = 0\n",
        "#             start_time = time.time()\n",
        "\n",
        "# def evaluate(eval_model, data_source):\n",
        "#     eval_model.eval() # 평가 모드를 시작합니다.\n",
        "#     total_loss = 0.\n",
        "#     ntokens = len(TEXT.vocab.stoi)\n",
        "#     with torch.no_grad():\n",
        "#         for i in range(0, data_source.size(0) - 1, bptt):\n",
        "#             data, targets = get_batch(data_source, i)\n",
        "#             output = eval_model(data)\n",
        "#             output_flat = output.view(-1, ntokens)\n",
        "#             total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "#     return total_loss / (len(data_source) - 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmbnOw_YTj04"
      },
      "source": [
        "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': train_token,\n",
        "        'dec_inputs': label_token[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
        "    },\n",
        "    {\n",
        "        'outputs': label_token[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2MT1lyXKzzg"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "  \n",
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "  \n",
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4kPBiQkLF8B"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.2\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaxW16nJLK9E"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rMmAF6jLONf"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XDXvuc8Tj6J"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udey1pWqABXR"
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVHbISTxTj8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bad302d-f151-4953-f181-62ef314fc018"
      },
      "source": [
        "model.fit(dataset, epochs=EPOCHS)\n",
        "# if tf.test.is_gpu_available():\n",
        "#   print(\"On GPU:\")\n",
        "#   with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
        "#     model.fit(dataset, epochs=EPOCHS)\n",
        "#     # assert x.device.endswith(\"GPU:0\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "223/223 [==============================] - 111s 458ms/step - loss: 0.6450 - accuracy: 0.0115\n",
            "Epoch 2/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.2901 - accuracy: 0.0554\n",
            "Epoch 3/20\n",
            "223/223 [==============================] - 103s 463ms/step - loss: 0.1886 - accuracy: 0.0628\n",
            "Epoch 4/20\n",
            "223/223 [==============================] - 103s 463ms/step - loss: 0.1321 - accuracy: 0.0696\n",
            "Epoch 5/20\n",
            "223/223 [==============================] - 103s 461ms/step - loss: 0.0973 - accuracy: 0.0742\n",
            "Epoch 6/20\n",
            "223/223 [==============================] - 103s 463ms/step - loss: 0.0775 - accuracy: 0.0768\n",
            "Epoch 7/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0674 - accuracy: 0.0780\n",
            "Epoch 8/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0623 - accuracy: 0.0786\n",
            "Epoch 9/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0587 - accuracy: 0.0791\n",
            "Epoch 10/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0567 - accuracy: 0.0794\n",
            "Epoch 11/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0551 - accuracy: 0.0795\n",
            "Epoch 12/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0538 - accuracy: 0.0799\n",
            "Epoch 13/20\n",
            "223/223 [==============================] - 103s 463ms/step - loss: 0.0526 - accuracy: 0.0800\n",
            "Epoch 14/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0517 - accuracy: 0.0801\n",
            "Epoch 15/20\n",
            "223/223 [==============================] - 103s 463ms/step - loss: 0.0506 - accuracy: 0.0803\n",
            "Epoch 16/20\n",
            "223/223 [==============================] - 104s 464ms/step - loss: 0.0499 - accuracy: 0.0805\n",
            "Epoch 17/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0487 - accuracy: 0.0807\n",
            "Epoch 18/20\n",
            "223/223 [==============================] - 103s 463ms/step - loss: 0.0481 - accuracy: 0.0808\n",
            "Epoch 19/20\n",
            "223/223 [==============================] - 103s 461ms/step - loss: 0.0472 - accuracy: 0.0810\n",
            "Epoch 20/20\n",
            "223/223 [==============================] - 103s 462ms/step - loss: 0.0461 - accuracy: 0.0813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5f65e6c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3L0LlZK0reo"
      },
      "source": [
        "# best_val_loss = float(\"inf\")\n",
        "# epochs = 1 # 에포크 수\n",
        "# best_model = None\n",
        "\n",
        "# for epoch in range(1, epochs + 1):\n",
        "#     epoch_start_time = time.time()\n",
        "#     train()\n",
        "#     val_loss = evaluate(model, val_data)\n",
        "#     print('-' * 89)\n",
        "#     print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "#           'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "#                                      val_loss, math.exp(val_loss)))\n",
        "#     print('-' * 89)\n",
        "\n",
        "#     if val_loss < best_val_loss:\n",
        "#         best_val_loss = val_loss\n",
        "#         best_model = model\n",
        "\n",
        "#     scheduler.step()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EnZzdWL_718"
      },
      "source": [
        "name = 'Transformer_' + str(EPOCHS) + '.h5'\n",
        "# name = 'Transformer_' + str(epochs) + '.pt'"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctgBKzffNI58"
      },
      "source": [
        "model.save_weights(path+f'Transformer_{EPOCHS}_weights.ckpt')\n",
        "# model.save(path + name)\n",
        "# torch.save(model, path+name)\n",
        "# tf.saved_model.save(model, path+name)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR-vDKccX0Xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d917d1-d871-4cb0-a775-4f8594659d33"
      },
      "source": [
        "# model = tf.keras.models.load_model(path + name)\n",
        "model.load_weights(path+f'Transformer_{EPOCHS}_weights.ckpt')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc5f623b2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvgs4Pf4TkEC"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 예측 시작\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
        "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "#   print('Input: {}'.format(sentence))\n",
        "#   print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n",
        "\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYuXOFHwYcc-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "db4c2900-adfc-4ebc-a9dc-44ede7deb683"
      },
      "source": [
        "filtering_train_df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>label</th>\n",
              "      <th>token_len</th>\n",
              "      <th>token_len_cate</th>\n",
              "      <th>split_train_token</th>\n",
              "      <th>split_label_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S/4 CACTI CANDLES&amp;&amp;HOLIDAY FUN LUDO&amp;&amp;CAT BOWL&amp;...</td>\n",
              "      <td>PINK FLORAL FELTCRAFT SHOULDER BAG</td>\n",
              "      <td>11</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; S/4 CACTI CANDLES &lt;esp&gt; HOLIDAY FUN LUDO...</td>\n",
              "      <td>&lt;esp&gt; PINK FLORAL FELTCRAFT SHOULDER BAG &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SILK PURSE RUSSIAN DOLL BLUE&amp;&amp;LOVE BUILDING BL...</td>\n",
              "      <td>BLUE GREEN EMBROIDERY COSMETIC BAG</td>\n",
              "      <td>19</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; SILK PURSE RUSSIAN DOLL BLUE &lt;esp&gt; LOVE ...</td>\n",
              "      <td>&lt;esp&gt; BLUE GREEN EMBROIDERY COSMETIC BAG &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RIBBON REEL STRIPES DESIGN&amp;&amp;RIBBON REEL SPOTS ...</td>\n",
              "      <td>GLASS ETCHED T-LIGHT HOLDER MEDIUM</td>\n",
              "      <td>17</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; RIBBON REEL STRIPES DESIGN &lt;esp&gt; RIBBON ...</td>\n",
              "      <td>&lt;esp&gt; GLASS ETCHED T-LIGHT HOLDER MEDIUM &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ETCHED GLASS COASTER&amp;&amp;PACK OF 20 SKULL PAPER N...</td>\n",
              "      <td>HANGING HEART ZINC T-LIGHT HOLDER</td>\n",
              "      <td>18</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; ETCHED GLASS COASTER &lt;esp&gt; PACK OF 20 SK...</td>\n",
              "      <td>&lt;esp&gt; HANGING HEART ZINC T-LIGHT HOLDER &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PLASTERS IN TIN WOODLAND ANIMALS&amp;&amp;PLASTERS IN ...</td>\n",
              "      <td>LUNCH BAG SPACEBOY DESIGN</td>\n",
              "      <td>18</td>\n",
              "      <td>0:100</td>\n",
              "      <td>&lt;esp&gt; PLASTERS IN TIN WOODLAND ANIMALS &lt;esp&gt; P...</td>\n",
              "      <td>&lt;esp&gt; LUNCH BAG SPACEBOY DESIGN &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               train  ...                               split_label_token\n",
              "0  S/4 CACTI CANDLES&&HOLIDAY FUN LUDO&&CAT BOWL&...  ...  <esp> PINK FLORAL FELTCRAFT SHOULDER BAG <esp>\n",
              "1  SILK PURSE RUSSIAN DOLL BLUE&&LOVE BUILDING BL...  ...  <esp> BLUE GREEN EMBROIDERY COSMETIC BAG <esp>\n",
              "2  RIBBON REEL STRIPES DESIGN&&RIBBON REEL SPOTS ...  ...  <esp> GLASS ETCHED T-LIGHT HOLDER MEDIUM <esp>\n",
              "3  ETCHED GLASS COASTER&&PACK OF 20 SKULL PAPER N...  ...   <esp> HANGING HEART ZINC T-LIGHT HOLDER <esp>\n",
              "4  PLASTERS IN TIN WOODLAND ANIMALS&&PLASTERS IN ...  ...           <esp> LUNCH BAG SPACEBOY DESIGN <esp>\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k592OU1EY7xc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70552716-3226-4a0a-e29e-96c176ce6e42"
      },
      "source": [
        "predict(filtering_train_df['split_label_token'][2])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> RED SPOTTY COIR DOORMAT <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Br9KixTkFc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389,
          "referenced_widgets": [
            "3fc94f669f9d4e478ceda1b183ff0352",
            "61b1ea5f0c064860bfbcd4251a1bc3eb",
            "61fea5e35eef4271bbba41dd0021ac5b",
            "bb3ab6e6e6da4141b8a0b0b43821ca67",
            "b71bad4901bf4f149ae7e13dfd05891b",
            "41df36ec45834950a012d5a8fb5bcfe0",
            "45f7508470274d5994612a43ba100b0f",
            "fafcc35bdc5f4b07827c6671d738de5d"
          ]
        },
        "outputId": "3c90b26f-49e3-490c-9b0f-016d02ff3005"
      },
      "source": [
        "predict_item = [predict(i) for i in tqdm_notebook(filtering_train_df['split_train_token'])]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fc94f669f9d4e478ceda1b183ff0352",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=56964.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-2e81786a139c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltering_train_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_train_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-2e81786a139c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltering_train_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_train_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-7fa7b36e7c1b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   predicted_sentence = tokenizer.decode(\n",
            "\u001b[0;32m<ipython-input-38-7fa7b36e7c1b>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# 디코더의 예측 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 현재(마지막) 시점의 예측 단어를 받아온다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5dd439130a4e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# scaled dot-product attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mscaled_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mscaled_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5dd439130a4e>\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(query, key, value, mask)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# scale matmul_qk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_qk\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1020\u001b[0m       skip_on_eager=False) as name:\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1023\u001b[0m                                                   stack(strides))\n\u001b[1;32m   1024\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_autopacking_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m   \u001b[0;34m\"\"\"Tensor conversion function that automatically packs arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mas_ref\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_should_not_autopack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m   \u001b[0minferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dtype_from_nested_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_should_not_autopack\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m   1506\u001b[0m   \u001b[0;31m# pylint: disable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m   \u001b[0;31m# TODO(slebedev): add nest.all?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_NON_AUTOPACKABLE_TYPES\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m   \u001b[0;31m# pylint: enable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjlcS-7hphRs"
      },
      "source": [
        "filtering_train_df['predict_item'] = predict_item"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBtGxj_ppnI7"
      },
      "source": [
        "pd.Series([i in list(filtering_train_df['split_label_token']) for i in filtering_train_df['predict_item']]).value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7emrtFTn6XVB"
      },
      "source": [
        "filtering_train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Chc856EAVP"
      },
      "source": [
        "filtering_train_df.pop('token_len')\n",
        "filtering_train_df.pop('token_len_cate')\n",
        "filtering_train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEzYKjgLc0x6"
      },
      "source": [
        "filtering_train_df.to_csv(path + 'Transformer_outputs.csv', mode='w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ammn_7esech4"
      },
      "source": [
        "filtering_test_df['split_train_token'] = ['<esp> ' + i.strip().replace('&&', ' <esp> ') + ' <esp>' for i in filtering_test_df['train']]\n",
        "filtering_test_df['split_label_token'] = ['<esp> ' + i.strip() + ' <esp>' for i in filtering_test_df['label']]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "0e7843f066d84df6b4f5ecba8bace362",
            "45c535617eee45c29f534b0c5caf0013",
            "03f481cd91fa4d168275e1afeb56c750",
            "8424a98b7621427bb707a6b6937b9b7b",
            "f2e2f186695b4aa39320fafedb23617a",
            "a485b6c166ae4662b1a827c91ebf3db4",
            "3522afecae2642ad869b75e6b4fb65fe",
            "c413906413e54659b430646a7982e457"
          ]
        },
        "id": "3kA-UfGzeHIY",
        "outputId": "7a031cd7-309a-4f08-89b8-c972ca0fa618"
      },
      "source": [
        "predict_item_test = [predict(i) for i in tqdm_notebook(filtering_test_df['split_train_token'])]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e7843f066d84df6b4f5ecba8bace362",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14241.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1bg7taWe3Vl",
        "outputId": "1fdb699f-e2c7-44aa-d650-9487eae6303e"
      },
      "source": [
        "filtering_test_df['predict_item'] = predict_item_test\n",
        "pd.Series([i in list(filtering_test_df['split_label_token']) for i in filtering_test_df['predict_item']]).value_counts()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     14040\n",
              "False      201\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "3wGK8SfJfCLv",
        "outputId": "3a376ee3-130d-4fd3-903c-011bcf35622f"
      },
      "source": [
        "filtering_test_df.pop('token_len')\n",
        "filtering_test_df.pop('token_len_cate')\n",
        "filtering_test_df.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>label</th>\n",
              "      <th>split_train_token</th>\n",
              "      <th>split_label_token</th>\n",
              "      <th>predict_item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56964</th>\n",
              "      <td>ENAMEL FLOWER JUG CREAM&amp;&amp;DOOR MAT FAIRY CAKE&amp;&amp;...</td>\n",
              "      <td>RED SPOTTY TABLECLOTH</td>\n",
              "      <td>&lt;esp&gt; ENAMEL FLOWER JUG CREAM &lt;esp&gt; DOOR MAT F...</td>\n",
              "      <td>&lt;esp&gt; RED SPOTTY TABLECLOTH &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; ENAMEL BREAD BIN CREAM &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56965</th>\n",
              "      <td>GAOLERS KEYS DECORATIVE GARDEN&amp;&amp;HAND OPEN SHAP...</td>\n",
              "      <td>SET OF 2 FANCY FONT TEA TOWELS</td>\n",
              "      <td>&lt;esp&gt; GAOLERS KEYS DECORATIVE GARDEN &lt;esp&gt; HAN...</td>\n",
              "      <td>&lt;esp&gt; SET OF 2 FANCY FONT TEA TOWELS &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; PAPER BUNTING RETRO SPOTS &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56966</th>\n",
              "      <td>SET OF 9 HEART SHAPED BALLOONS&amp;&amp;SET OF 9 BLACK...</td>\n",
              "      <td>CERAMIC CHERRY CAKE MONEY BANK</td>\n",
              "      <td>&lt;esp&gt; SET OF 9 HEART SHAPED BALLOONS &lt;esp&gt; SET...</td>\n",
              "      <td>&lt;esp&gt; CERAMIC CHERRY CAKE MONEY BANK &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; ASSTD DESIGN BUBBLE GUM RING &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56967</th>\n",
              "      <td>HANGING HEART ZINC T-LIGHT HOLDER&amp;&amp;OPULENT VEL...</td>\n",
              "      <td>COLOUR GLASS. STAR T-LIGHT HOLDER</td>\n",
              "      <td>&lt;esp&gt; HANGING HEART ZINC T-LIGHT HOLDER &lt;esp&gt; ...</td>\n",
              "      <td>&lt;esp&gt; COLOUR GLASS. STAR T-LIGHT HOLDER &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; HANGING HEART ZINC T-LIGHT HOLDER &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56968</th>\n",
              "      <td>BAKING SET 9 PIECE RETROSPOT&amp;&amp;PARTY INVITES WO...</td>\n",
              "      <td>PARTY INVITES FOOTBALL</td>\n",
              "      <td>&lt;esp&gt; BAKING SET 9 PIECE RETROSPOT &lt;esp&gt; PARTY...</td>\n",
              "      <td>&lt;esp&gt; PARTY INVITES FOOTBALL &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; PARTY INVITES WOODLAND &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   train  ...                                   predict_item\n",
              "56964  ENAMEL FLOWER JUG CREAM&&DOOR MAT FAIRY CAKE&&...  ...             <esp> ENAMEL BREAD BIN CREAM <esp>\n",
              "56965  GAOLERS KEYS DECORATIVE GARDEN&&HAND OPEN SHAP...  ...          <esp> PAPER BUNTING RETRO SPOTS <esp>\n",
              "56966  SET OF 9 HEART SHAPED BALLOONS&&SET OF 9 BLACK...  ...       <esp> ASSTD DESIGN BUBBLE GUM RING <esp>\n",
              "56967  HANGING HEART ZINC T-LIGHT HOLDER&&OPULENT VEL...  ...  <esp> HANGING HEART ZINC T-LIGHT HOLDER <esp>\n",
              "56968  BAKING SET 9 PIECE RETROSPOT&&PARTY INVITES WO...  ...             <esp> PARTY INVITES WOODLAND <esp>\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "sRmBz3pWM_DP",
        "outputId": "43d6f2a9-9411-41c3-9ff2-5964066df857"
      },
      "source": [
        "filtering_test_df"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>label</th>\n",
              "      <th>split_train_token</th>\n",
              "      <th>split_label_token</th>\n",
              "      <th>predict_item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENAMEL FLOWER JUG CREAM&amp;&amp;DOOR MAT FAIRY CAKE&amp;&amp;...</td>\n",
              "      <td>RED SPOTTY TABLECLOTH</td>\n",
              "      <td>&lt;esp&gt; ENAMEL FLOWER JUG CREAM &lt;esp&gt; DOOR MAT F...</td>\n",
              "      <td>&lt;esp&gt; RED SPOTTY TABLECLOTH &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; ENAMEL BREAD BIN CREAM &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GAOLERS KEYS DECORATIVE GARDEN&amp;&amp;HAND OPEN SHAP...</td>\n",
              "      <td>SET OF 2 FANCY FONT TEA TOWELS</td>\n",
              "      <td>&lt;esp&gt; GAOLERS KEYS DECORATIVE GARDEN &lt;esp&gt; HAN...</td>\n",
              "      <td>&lt;esp&gt; SET OF 2 FANCY FONT TEA TOWELS &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; PAPER BUNTING RETRO SPOTS &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SET OF 9 HEART SHAPED BALLOONS&amp;&amp;SET OF 9 BLACK...</td>\n",
              "      <td>CERAMIC CHERRY CAKE MONEY BANK</td>\n",
              "      <td>&lt;esp&gt; SET OF 9 HEART SHAPED BALLOONS &lt;esp&gt; SET...</td>\n",
              "      <td>&lt;esp&gt; CERAMIC CHERRY CAKE MONEY BANK &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; ASSTD DESIGN BUBBLE GUM RING &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HANGING HEART ZINC T-LIGHT HOLDER&amp;&amp;OPULENT VEL...</td>\n",
              "      <td>COLOUR GLASS. STAR T-LIGHT HOLDER</td>\n",
              "      <td>&lt;esp&gt; HANGING HEART ZINC T-LIGHT HOLDER &lt;esp&gt; ...</td>\n",
              "      <td>&lt;esp&gt; COLOUR GLASS. STAR T-LIGHT HOLDER &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; HANGING HEART ZINC T-LIGHT HOLDER &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BAKING SET 9 PIECE RETROSPOT&amp;&amp;PARTY INVITES WO...</td>\n",
              "      <td>PARTY INVITES FOOTBALL</td>\n",
              "      <td>&lt;esp&gt; BAKING SET 9 PIECE RETROSPOT &lt;esp&gt; PARTY...</td>\n",
              "      <td>&lt;esp&gt; PARTY INVITES FOOTBALL &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; PARTY INVITES WOODLAND &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14236</th>\n",
              "      <td>ENAMEL MEASURING JUG CREAM&amp;&amp;CREAM HEART CARD H...</td>\n",
              "      <td>IVORY KITCHEN SCALES</td>\n",
              "      <td>&lt;esp&gt; ENAMEL MEASURING JUG CREAM &lt;esp&gt; CREAM H...</td>\n",
              "      <td>&lt;esp&gt; IVORY KITCHEN SCALES &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; DOOR MAT UNION FLAG &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14237</th>\n",
              "      <td>TOILET METAL SIGN&amp;&amp;SAVE THE PLANET MUG&amp;&amp;KINGS ...</td>\n",
              "      <td>POTTERING IN THE SHED METAL SIGN</td>\n",
              "      <td>&lt;esp&gt; TOILET METAL SIGN &lt;esp&gt; SAVE THE PLANET ...</td>\n",
              "      <td>&lt;esp&gt; POTTERING IN THE SHED METAL SIGN &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; BATHROOM METAL SIGN &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14238</th>\n",
              "      <td>IVORY HANGING DECORATION  HEART&amp;&amp;HEART IVORY T...</td>\n",
              "      <td>COLOUR GLASS T-LIGHT HOLDER HANGING</td>\n",
              "      <td>&lt;esp&gt; IVORY HANGING DECORATION  HEART &lt;esp&gt; HE...</td>\n",
              "      <td>&lt;esp&gt; COLOUR GLASS T-LIGHT HOLDER HANGING &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; HEART T-LIGHT HOLDER &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14239</th>\n",
              "      <td>LAVENDER SCENTED FABRIC HEART&amp;&amp;PLACE SETTING W...</td>\n",
              "      <td>MURANO STYLE GLASS BRACELET PINK</td>\n",
              "      <td>&lt;esp&gt; LAVENDER SCENTED FABRIC HEART &lt;esp&gt; PLAC...</td>\n",
              "      <td>&lt;esp&gt; MURANO STYLE GLASS BRACELET PINK &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; RED GINGHAM ROSE JEWELLERY BOX &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14240</th>\n",
              "      <td>FELT EGG COSY CHICKEN&amp;&amp;APPLE BATH SPONGE&amp;&amp;RED ...</td>\n",
              "      <td>VINTAGE CARAVAN GIFT WRAP</td>\n",
              "      <td>&lt;esp&gt; FELT EGG COSY CHICKEN &lt;esp&gt; APPLE BATH S...</td>\n",
              "      <td>&lt;esp&gt; VINTAGE CARAVAN GIFT WRAP &lt;esp&gt;</td>\n",
              "      <td>&lt;esp&gt; SPACEBOY GIFT WRAP &lt;esp&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14241 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   train  ...                                   predict_item\n",
              "0      ENAMEL FLOWER JUG CREAM&&DOOR MAT FAIRY CAKE&&...  ...             <esp> ENAMEL BREAD BIN CREAM <esp>\n",
              "1      GAOLERS KEYS DECORATIVE GARDEN&&HAND OPEN SHAP...  ...          <esp> PAPER BUNTING RETRO SPOTS <esp>\n",
              "2      SET OF 9 HEART SHAPED BALLOONS&&SET OF 9 BLACK...  ...       <esp> ASSTD DESIGN BUBBLE GUM RING <esp>\n",
              "3      HANGING HEART ZINC T-LIGHT HOLDER&&OPULENT VEL...  ...  <esp> HANGING HEART ZINC T-LIGHT HOLDER <esp>\n",
              "4      BAKING SET 9 PIECE RETROSPOT&&PARTY INVITES WO...  ...             <esp> PARTY INVITES WOODLAND <esp>\n",
              "...                                                  ...  ...                                            ...\n",
              "14236  ENAMEL MEASURING JUG CREAM&&CREAM HEART CARD H...  ...                <esp> DOOR MAT UNION FLAG <esp>\n",
              "14237  TOILET METAL SIGN&&SAVE THE PLANET MUG&&KINGS ...  ...                <esp> BATHROOM METAL SIGN <esp>\n",
              "14238  IVORY HANGING DECORATION  HEART&&HEART IVORY T...  ...               <esp> HEART T-LIGHT HOLDER <esp>\n",
              "14239  LAVENDER SCENTED FABRIC HEART&&PLACE SETTING W...  ...     <esp> RED GINGHAM ROSE JEWELLERY BOX <esp>\n",
              "14240  FELT EGG COSY CHICKEN&&APPLE BATH SPONGE&&RED ...  ...                 <esp> SPACEBOY GIFT WRAP <esp>\n",
              "\n",
              "[14241 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q2ZolVofCH6"
      },
      "source": [
        "filtering_test_df.to_csv(path + 'Transformer_test_outputs.csv', mode='w')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoMgO5HDflAD",
        "outputId": "fae7564e-d8c5-4534-ec77-5c850811fb49"
      },
      "source": [
        "sum = 0\n",
        "l = len(filtering_test_df)\n",
        "for i in range(l):\n",
        "    if filtering_test_df['split_label_token'][i] == filtering_test_df['predict_item'][i]:\n",
        "        sum += 1\n",
        "\n",
        "acc = sum / l\n",
        "acc"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02324274980689558"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdGg31JkfL-w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HOPjsUK4G1E3",
        "outputId": "badff85f-48a3-4cde-94c7-6757b88642ff"
      },
      "source": [
        "predict('<esp> 집에 가고 싶어 <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> ASSORTED COLOUR BIRD ORNAMENT <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXJtz7IUc0rM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dd945cd1-aea2-4f26-d847-3374877a65e5"
      },
      "source": [
        "predict('<esp> 지갑 <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> ASSORTED COLOUR BIRD ORNAMENT <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvNzgvHgHNB7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e81e4b0b-6db5-40bd-a71c-bec03c8f0ea6"
      },
      "source": [
        "predict('<esp> 이경전 <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> ASSORTED TUTTI FRUTTI SMALL PURSE <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Mz022XmBHGyl",
        "outputId": "0018b793-160c-4da6-a2b2-6538c4ed7ab2"
      },
      "source": [
        "predict('<esp> 집에 가고 싶다 <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> ASSORTED SANSKRIT MINI NOTEBOOK <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T15J2h0-YxQh",
        "outputId": "666c2b71-2293-4018-c208-a9e996dc94cf"
      },
      "source": [
        "predict('''<esp> AGED GLASS SILVER T-LIGHT HOLDER <esp> ASSORTED COLOUR T-LIGHT HOLDER <esp> RIDGED GLASS T-LIGHT HOLDER <esp> BLACK SILVER FLOWER T-LIGHT HOLDER <esp> BLACK CANDELABRA T-LIGHT HOLDER <esp>''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> RETRO SPOT LARGE MILK JUG <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uRBYO9kLZPYC",
        "outputId": "51210aa3-3fb0-4304-b926-724fb84f84eb"
      },
      "source": [
        "predict('<esp> AGED GLASS SILVER T-LIGHT HOLDER <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> WHITE HANGING HEART T-LIGHT HOLDER <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1CmiwEoiZYnB",
        "outputId": "d7e433a2-fb2d-44ae-896c-002f53f84c57"
      },
      "source": [
        "predict('<esp> ASSORTED COLOUR T-LIGHT HOLDER <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> SET/5 RED SPOTTY LID GLASS BOWLS <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yjl20nVbZedv",
        "outputId": "1d0e48b9-0db6-41d6-b07b-582cbef20ce3"
      },
      "source": [
        "predict('<esp> BLACK SILVER FLOWER T-LIGHT HOLDER <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> SILVER HANGING T-LIGHT HOLDER <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "85UvrTtRZjZt",
        "outputId": "e8879fce-2f35-451b-caaf-b1c29215753b"
      },
      "source": [
        "predict('<esp> BLACK CANDELABRA T-LIGHT HOLDER <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> STEEL SWEETHEART ROUND TABLE CREAM <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SOOT4pELZpIw",
        "outputId": "c55ec01c-f73a-4f6e-c9ed-340c773e022f"
      },
      "source": [
        "predict('<esp> AGED GLASS SILVER T-LIGHT HOLDER <esp> ASSORTED COLOUR T-LIGHT HOLDER <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> VICTORIAN GLASS HANGING T-LIGHT <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kEz6Wwb7Zw8F",
        "outputId": "5a72da79-cff1-46b4-bac9-fbbbf728d2b8"
      },
      "source": [
        "predict('<esp> AGED GLASS SILVER T-LIGHT HOLDER <esp> BLACK SILVER FLOWER T-LIGHT HOLDER <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> WHITE HANGING HEART T-LIGHT HOLDER <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s-FruQSnZ_O0",
        "outputId": "05e534e0-a5f5-487f-ebbc-63c01ff73270"
      },
      "source": [
        "predict('<esp> ASSORTED COLOUR T-LIGHT HOLDER <esp> RIDGED GLASS T-LIGHT HOLDER <esp> BLACK SILVER FLOWER T-LIGHT HOLDER <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> SMALL POPCORN HOLDER <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AGhaZzuGHGpX",
        "outputId": "e3de8b94-88d7-4d00-dcd4-75ff315cca96"
      },
      "source": [
        "predict('<esp> I wanna go home <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> ASSORTED COLOUR BIRD ORNAMENT <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aTz_mOGJHGMZ",
        "outputId": "fd8ae0b9-7462-495e-f0c9-3ce8bde7c122"
      },
      "source": [
        "predict('<esp> Lee Kyoungjun <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> ASSORTED ELEPHANT TOY WITH BLUE T-SHIRT <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7Vb2j-CXMsuF",
        "outputId": "e44b8c8c-6901-4f5e-f63c-3470d3872ddc"
      },
      "source": [
        "predict('<esp> lee kyoungjun <esp> OWL DOORSTOP <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> VICTORIAN SEWING BOX SMALL <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GBFk_bg-PQ1r",
        "outputId": "1f514e73-a01f-4916-feff-fd07fa2909e0"
      },
      "source": [
        "predict('<esp> lee kyoungjun <esp> OWL DOORSTOP <esp> DOOR MAT RED SPOT <esp> RED RETROSPOT CAKE STANDROSE CARAVAN DOORSTOP <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> SET OF 3 COLOURED  FLYING DUCKS <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1uKbEPDxPX0b",
        "outputId": "d22dbe8e-2d1b-4bf3-df60-f98e4436c742"
      },
      "source": [
        "predict('<esp> OWL DOORSTOP <esp> DOOR MAT RED SPOT <esp> RED RETROSPOT CAKE STANDROSE CARAVAN DOORSTOP <esp> lee kyoungjun <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> SET OF 12 COFFEE BOTANICAL T-LIGHTS <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uErHfw2lHcYp",
        "outputId": "8ba29282-60a6-47fe-e64d-e8a3925e4b9c"
      },
      "source": [
        "predict('<esp> 이경전 <esp> 교수님 <esp> 집에 가고 싶어 <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> SMALL ROUND CUT GLASS CANDLESTICK <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SaqJPMAdHcVo",
        "outputId": "7e751775-1bad-466d-b4e4-8b5b3bb396fc"
      },
      "source": [
        "predict('<esp> 집에 <esp> 가고 <esp> 싶다 <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> COFFEE MUG PEARS  DESIGN <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ObyNry30McmK",
        "outputId": "c73cf937-067a-4088-8ad1-e2b014ae66ba"
      },
      "source": [
        "predict('<esp> I wanna <esp> go <esp> home <esp>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> LOVE GARLAND PAINTED ZINC <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mr-zFBiXHcTT",
        "outputId": "420082e7-cf74-4cef-a6fd-2071af7ffc71"
      },
      "source": [
        "predict('''<esp> EIGHT PIECE DINOSAUR SET <esp> WRAP,SUKI AND FRIENDS <esp> CAMOUFLAGE LED TORCH <esp> 60 GOLD AND SILVER FAIRY CAKE CASES <esp> PACK 6 HEART/ICE-CREAM PATCHES <esp> WHITE HANGING HEART T-LIGHT HOLDER <esp> LUNCH BAG SUKI  DESIGN <esp> SET OF 20 KIDS COOKIE CUTTERS <esp> METAL SIGN TAKE IT OR LEAVE IT <esp> GREEN GINGHAM FLOWER JEWELLERY BOX <esp> RED GINGHAM ROSE JEWELLERY BOX <esp> GIN + TONIC DIET METAL SIGN <esp> I'M ON HOLIDAY METAL SIGN <esp> CERAMIC BIRDHOUSE RED ROOF SMALL <esp> SET OF 2 TINS VINTAGE BATHROOM <esp> DOOR MAT HEARTS <esp>''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> EIGHT PIECE CREEPY CRAWLIE SET <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yR3IysQSHcPT",
        "outputId": "c9ad4d4c-840b-43e8-e923-af8fa5cc7d72"
      },
      "source": [
        "predict('''<esp> EIGHT PIECE DINOSAUR SET <esp> WRAP,SUKI AND FRIENDS <esp> CAMOUFLAGE LED TORCH <esp> 60 GOLD AND SILVER FAIRY CAKE CASES <esp> PACK 6 HEART/ICE-CREAM PATCHES <esp> WHITE HANGING HEART T-LIGHT HOLDER <esp> LUNCH BAG SUKI  DESIGN <esp> SET OF 20 KIDS COOKIE CUTTERS <esp> METAL SIGN TAKE IT OR LEAVE IT <esp> GREEN GINGHAM FLOWER JEWELLERY BOX <esp> RED GINGHAM ROSE JEWELLERY BOX <esp> GIN + TONIC DIET METAL SIGN <esp> ON HOLIDAY METAL SIGN <esp> CERAMIC BIRDHOUSE RED ROOF SMALL <esp> SET OF 2 TINS VINTAGE BATHROOM <esp> EIGHT PIECE CREEPY CRAWLIE SET <esp> EIGHT PIECE DINOSAUR SET <esp> WRAP,SUKI AND FRIENDS <esp>''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> EIGHT PIECE DINOSAUR SET <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "n7c9kQpPHcL7",
        "outputId": "424d8709-ef91-4aef-8bb9-2d331155cf9a"
      },
      "source": [
        "predict('''<esp> EIGHT PIECE DINOSAUR SET <esp> WRAP,SUKI AND FRIENDS <esp> CAMOUFLAGE LED TORCH <esp> 60 GOLD AND SILVER FAIRY CAKE CASES <esp> PACK 6 HEART/ICE-CREAM PATCHES <esp> WHITE HANGING HEART T-LIGHT HOLDER <esp> LUNCH BAG SUKI  DESIGN <esp> SET OF 20 KIDS COOKIE CUTTERS <esp> METAL SIGN TAKE IT OR LEAVE IT <esp> GREEN GINGHAM FLOWER JEWELLERY BOX <esp> RED GINGHAM ROSE JEWELLERY BOX <esp> GIN + TONIC DIET METAL SIGN <esp> I'M ON HOLIDAY METAL SIGN <esp> CERAMIC BIRDHOUSE RED ROOF SMALL <esp> SET OF 2 TINS VINTAGE BATHROOM <esp> DOOR MAT HEARTS <esp> EIGHT PIECE CREEPY CRAWLIE SET <esp>''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> EIGHT PIECE CREEPY CRAWLIE SET <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hoIdaEegHcH2",
        "outputId": "51da8b19-65e1-4eb0-9293-fe99dbb59790"
      },
      "source": [
        "predict('''<esp> PLEASE ONE PERSON METAL SIGN <esp> 3 STRIPEY MICE FELTCRAFT <esp> DOOR MAT HEARTS <esp> DOOR MAT UNION FLAG <esp>''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> FELTCRAFT 6 FLOWER FRIENDS <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QhPqkb_YHcD-",
        "outputId": "25e08b91-e5eb-48b9-8541-2df752b05f7c"
      },
      "source": [
        "predict('''<esp> PLEASE ONE PERSON METAL SIGN <esp> 3 STRIPEY MICE FELTCRAFT <esp> DOOR MAT HEARTS <esp> DOOR MAT UNION FLAG <esp> FELTCRAFT 6 FLOWER FRIENDS <esp> EIGHT PIECE DINOSAUR SET <esp>''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<esp> STRAWBERRY CHARLOTTE BAG <esp>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4jBXgPKHcAP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2St4UFVxVqji"
      },
      "source": [
        "# def transformer(vocab_size, num_layers, dff,\n",
        "#                 d_model, num_heads, dropout,\n",
        "#                 name=\"transformer\", stats='train'):\n",
        "\n",
        "#   # 인코더의 입력\n",
        "#   inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "#   # 디코더의 입력\n",
        "#   dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "#   # 인코더의 패딩 마스크\n",
        "#   enc_padding_mask = tf.keras.layers.Lambda(\n",
        "#       create_padding_mask, output_shape=(1, 1, None),\n",
        "#       name='enc_padding_mask')(inputs)\n",
        "\n",
        "#   # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
        "#   look_ahead_mask = tf.keras.layers.Lambda(\n",
        "#       create_look_ahead_mask, output_shape=(1, None, None),\n",
        "#       name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "#   # 디코더의 패딩 마스크(두번째 서브층)\n",
        "#   dec_padding_mask = tf.keras.layers.Lambda(\n",
        "#       create_padding_mask, output_shape=(1, 1, None),\n",
        "#       name='dec_padding_mask')(inputs)\n",
        "\n",
        "#   # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
        "#   enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "#       d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "#   )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
        "\n",
        "#   # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
        "#   dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "#       d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "#   )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "#   # 다음 단어 예측을 위한 출력층\n",
        "#   if stats == 'train':\n",
        "#     outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "# #   elif stats == 'test':\n",
        "\n",
        "\n",
        "#   return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
        "\n",
        "\n",
        "# def create_padding_mask(x):\n",
        "#   mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "#   # (batch_size, 1, 1, key의 문장 길이)\n",
        "#   return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "\n",
        "# def create_look_ahead_mask(x):\n",
        "#   seq_len = tf.shape(x)[1]\n",
        "#   look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "#   padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
        "#   return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n",
        "\n",
        "# def encoder(vocab_size, num_layers, dff,\n",
        "#             d_model, num_heads, dropout,\n",
        "#             name=\"encoder\"):\n",
        "#   inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "#   # 인코더는 패딩 마스크 사용\n",
        "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "#   # 포지셔널 인코딩 + 드롭아웃\n",
        "#   embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "#   embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "#   embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "#   outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "#   # 인코더를 num_layers개 쌓기\n",
        "#   for i in range(num_layers):\n",
        "#     outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "#         dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
        "#     )([outputs, padding_mask])\n",
        "\n",
        "#   return tf.keras.Model(\n",
        "#       inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "\n",
        "# def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "#   inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "#   # 인코더는 패딩 마스크 사용\n",
        "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "#   # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
        "#   attention = MultiHeadAttention(\n",
        "#       d_model, num_heads, name=\"attention\")({\n",
        "#           'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "#           'mask': padding_mask # 패딩 마스크 사용\n",
        "#       })\n",
        "\n",
        "#   # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "#   attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "#   attention = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "#   # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
        "#   outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "#   outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "#   # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "#   outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "#   outputs = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "#   return tf.keras.Model(\n",
        "#       inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "\n",
        "# class PositionalEncoding(tf.keras.layers.Layer):\n",
        "#   def __init__(self, position, d_model):\n",
        "#     super(PositionalEncoding, self).__init__()\n",
        "#     self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "#   def get_angles(self, position, i, d_model):\n",
        "#     angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "#     return position * angles\n",
        "\n",
        "#   def positional_encoding(self, position, d_model):\n",
        "#     angle_rads = self.get_angles(\n",
        "#         position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "#         i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "#         d_model=d_model)\n",
        "\n",
        "#     # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
        "#     sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "#     # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
        "#     cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "#     angle_rads = np.zeros(angle_rads.shape)\n",
        "#     angle_rads[:, 0::2] = sines\n",
        "#     angle_rads[:, 1::2] = cosines\n",
        "#     pos_encoding = tf.constant(angle_rads)\n",
        "#     pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "#     print(pos_encoding.shape)\n",
        "#     return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "#   def call(self, inputs):\n",
        "#     return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "\n",
        "\n",
        "# class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "#   def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "#     super(MultiHeadAttention, self).__init__(name=name)\n",
        "#     self.num_heads = num_heads\n",
        "#     self.d_model = d_model\n",
        "\n",
        "#     assert d_model % self.num_heads == 0\n",
        "\n",
        "#     # d_model을 num_heads로 나눈 값.\n",
        "#     # 논문 기준 : 64\n",
        "#     self.depth = d_model // self.num_heads\n",
        "\n",
        "#     # WQ, WK, WV에 해당하는 밀집층 정의\n",
        "#     self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "#     self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "#     self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "#     # WO에 해당하는 밀집층 정의\n",
        "#     self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "#   # num_heads 개수만큼 q, k, v를 split하는 함수\n",
        "#   def split_heads(self, inputs, batch_size):\n",
        "#     inputs = tf.reshape(\n",
        "#         inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "#     return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "#   def call(self, inputs):\n",
        "#     query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "#         'value'], inputs['mask']\n",
        "#     batch_size = tf.shape(query)[0]\n",
        "\n",
        "#     # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
        "#     # q : (batch_size, query의 문장 길이, d_model)\n",
        "#     # k : (batch_size, key의 문장 길이, d_model)\n",
        "#     # v : (batch_size, value의 문장 길이, d_model)\n",
        "#     # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
        "#     query = self.query_dense(query)\n",
        "#     key = self.key_dense(key)\n",
        "#     value = self.value_dense(value)\n",
        "\n",
        "#     # 2. 헤드 나누기\n",
        "#     # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "#     # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "#     # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "#     query = self.split_heads(query, batch_size)\n",
        "#     key = self.split_heads(key, batch_size)\n",
        "#     value = self.split_heads(value, batch_size)\n",
        "\n",
        "#     # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
        "#     # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "#     scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "#     # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
        "#     scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "#     # 4. 헤드 연결(concatenate)하기\n",
        "#     # (batch_size, query의 문장 길이, d_model)\n",
        "#     concat_attention = tf.reshape(scaled_attention,\n",
        "#                                   (batch_size, -1, self.d_model))\n",
        "\n",
        "#     # 5. WO에 해당하는 밀집층 지나기\n",
        "#     # (batch_size, query의 문장 길이, d_model)\n",
        "#     outputs = self.dense(concat_attention)\n",
        "\n",
        "#     return outputs\n",
        "\n",
        "\n",
        "# def scaled_dot_product_attention(query, key, value, mask):\n",
        "#   # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "#   # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "#   # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "#   # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
        "\n",
        "#   # Q와 K의 곱. 어텐션 스코어 행렬.\n",
        "#   matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "#   # 스케일링\n",
        "#   # dk의 루트값으로 나눠준다.\n",
        "#   depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "#   logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "#   # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
        "#   # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
        "#   if mask is not None:\n",
        "#     logits += (mask * -1e9)\n",
        "\n",
        "#   # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
        "#   # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
        "#   attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "#   # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "#   output = tf.matmul(attention_weights, value)\n",
        "\n",
        "#   return output, attention_weights\n",
        "\n",
        "\n",
        "# def decoder(vocab_size, num_layers, dff,\n",
        "#             d_model, num_heads, dropout,\n",
        "#             name='decoder'):\n",
        "#   inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "#   enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "#   # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
        "#   look_ahead_mask = tf.keras.Input(\n",
        "#       shape=(1, None, None), name='look_ahead_mask')\n",
        "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "#   # 포지셔널 인코딩 + 드롭아웃\n",
        "#   embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "#   embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "#   embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "#   outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "#   # 디코더를 num_layers개 쌓기\n",
        "#   for i in range(num_layers):\n",
        "#     outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "#         dropout=dropout, name='decoder_layer_{}'.format(i),\n",
        "#     )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "#   return tf.keras.Model(\n",
        "#       inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "#       outputs=outputs,\n",
        "#       name=name)\n",
        "  \n",
        "\n",
        "# def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "#   inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "#   enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "\n",
        "#   # 룩어헤드 마스크(첫번째 서브층)\n",
        "#   look_ahead_mask = tf.keras.Input(\n",
        "#       shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "\n",
        "#   # 패딩 마스크(두번째 서브층)\n",
        "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "#   # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
        "#   attention1 = MultiHeadAttention(\n",
        "#       d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "#           'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "#           'mask': look_ahead_mask # 룩어헤드 마스크\n",
        "#       })\n",
        "\n",
        "#   # 잔차 연결과 층 정규화\n",
        "#   attention1 = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "#   # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
        "#   attention2 = MultiHeadAttention(\n",
        "#       d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "#           'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
        "#           'mask': padding_mask # 패딩 마스크\n",
        "#       })\n",
        "\n",
        "#   # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "#   attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "#   attention2 = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "#   # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
        "#   outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "#   outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "#   # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "#   outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "#   outputs = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "#   return tf.keras.Model(\n",
        "#       inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "#       outputs=outputs,\n",
        "#       name=name)\n",
        "  \n",
        "\n",
        "# class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "#   def __init__(self, d_model, warmup_steps=4000):\n",
        "#     super(CustomSchedule, self).__init__()\n",
        "#     self.d_model = d_model\n",
        "#     self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "#     self.warmup_steps = warmup_steps\n",
        "\n",
        "#   def __call__(self, step):\n",
        "#     arg1 = tf.math.rsqrt(step)\n",
        "#     arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "#     return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "\n",
        "# def loss_function(y_true, y_pred):\n",
        "#   y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "#   loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "#       from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "#   mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "#   loss = tf.multiply(loss, mask)\n",
        "\n",
        "#   return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxfKeJx8LTdH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}